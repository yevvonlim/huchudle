### 2024-04-12 EST 17:00 [Jaeho]

- What I did today
    * Jaeho discussed DiT in today weekly meeting. The presentation emphasized DiT's patchify and transformer decoder function.

- What I learn today
    * In patching, an image is divided into smaller patches, typically squares, each with a part of the original image. These patches are then flattened into sequences of vectors, which then go into the transformer model.

### 2024-04-12 EST 17:00  [Hailey]

- What I did today
  * Hailey prepared for presentation. 
  
- What I learned today
  * Hailey learned about how latent space works in Stable Diffusion model.
  * By implementing latent space, the image generation task got higher scalabilty because of the computing efficiency.
  * Latent space got a text embedding vector as a input, and do denoising process by Unet structure, then generate a latent vector that fed into the decoder, which is the image generation part.
